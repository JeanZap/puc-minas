{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71f4059b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk==3.8.1 in c:\\users\\jean_\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\jean_\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk==3.8.1) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\jean_\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk==3.8.1) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jean_\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk==3.8.1) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jean_\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk==3.8.1) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jean_\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk==3.8.1) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement unicode==1.3.8 (from versions: 2.6, 2.7, 2.8, 2.9)\n",
      "ERROR: No matching distribution found for unicode==1.3.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.2.2\n",
      "  Using cached scikit-learn-1.2.2.tar.gz (7.3 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [33 lines of output]\n",
      "      Partial import of sklearn during the build process.\n",
      "      Traceback (most recent call last):\n",
      "        File \"c:\\Users\\jean_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 389, in <module>\n",
      "          main()\n",
      "        File \"c:\\Users\\jean_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 373, in main\n",
      "          json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"c:\\Users\\jean_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 175, in prepare_metadata_for_build_wheel\n",
      "          return hook(metadata_directory, config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\jean_\\AppData\\Local\\Temp\\pip-build-env-b9rvhs6y\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 374, in prepare_metadata_for_build_wheel\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\jean_\\AppData\\Local\\Temp\\pip-build-env-b9rvhs6y\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 512, in run_setup\n",
      "          super().run_setup(setup_script=setup_script)\n",
      "        File \"C:\\Users\\jean_\\AppData\\Local\\Temp\\pip-build-env-b9rvhs6y\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 317, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 669, in <module>\n",
      "        File \"<string>\", line 663, in setup_package\n",
      "        File \"<string>\", line 597, in configure_extension_modules\n",
      "        File \"C:\\Users\\jean_\\AppData\\Local\\Temp\\pip-install-ilproxcf\\scikit-learn_a549df276e754c5289fd92a4e7771606\\sklearn\\_build_utils\\__init__.py\", line 47, in cythonize_extensions\n",
      "          basic_check_build()\n",
      "        File \"C:\\Users\\jean_\\AppData\\Local\\Temp\\pip-install-ilproxcf\\scikit-learn_a549df276e754c5289fd92a4e7771606\\sklearn\\_build_utils\\pre_build_helpers.py\", line 82, in basic_check_build\n",
      "          compile_test_program(code)\n",
      "        File \"C:\\Users\\jean_\\AppData\\Local\\Temp\\pip-install-ilproxcf\\scikit-learn_a549df276e754c5289fd92a4e7771606\\sklearn\\_build_utils\\pre_build_helpers.py\", line 38, in compile_test_program\n",
      "          ccompiler.compile(\n",
      "        File \"C:\\Users\\jean_\\AppData\\Local\\Temp\\pip-build-env-b9rvhs6y\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\compilers\\C\\msvc.py\", line 384, in compile\n",
      "          self.initialize()\n",
      "        File \"C:\\Users\\jean_\\AppData\\Local\\Temp\\pip-build-env-b9rvhs6y\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\compilers\\C\\msvc.py\", line 294, in initialize\n",
      "          vc_env = _get_vc_env(plat_spec)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\jean_\\AppData\\Local\\Temp\\pip-build-env-b9rvhs6y\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\compilers\\C\\msvc.py\", line 155, in _get_vc_env\n",
      "          raise DistutilsPlatformError(\n",
      "      distutils.errors.DistutilsPlatformError: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk==3.8.1\n",
    "%pip install unicode==1.3.8\n",
    "%pip install scikit-learn==1.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9363959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jean_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jean_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import math\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce74278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processa_texto(texto):\n",
    "    padrao = r\"\\w+(?:'\\w+)?|[^\\w\\s]\"\n",
    "    tokens_preprocessados = re.findall(padrao, texto)\n",
    "\n",
    "    tokens_preprocessados = [token.lower() for token in tokens_preprocessados]\n",
    "\n",
    "    portugues_stops = stopwords.words(\"portuguese\")\n",
    "\n",
    "    tokens_preprocessados = [\n",
    "        token for token in tokens_preprocessados if token not in portugues_stops\n",
    "    ]\n",
    "\n",
    "    tokens_preprocessados = [\n",
    "        re.sub(r\"\\d+\", \"\", token) for token in tokens_preprocessados\n",
    "    ]\n",
    "\n",
    "    tokens_preprocessados = [\n",
    "        token for token in tokens_preprocessados if token not in string.punctuation\n",
    "    ]\n",
    "\n",
    "    tokens_preprocessados = [unidecode(token) for token in tokens_preprocessados]\n",
    "\n",
    "    return \" \".join(tokens_preprocessados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6880ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_1 = pre_processa_texto(\"O gato comeu o rato\")\n",
    "texto_2 = pre_processa_texto(\"O rato comeu a comida do gato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8750f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similaridade_jaccard(a, b):\n",
    "    intersecao = len(set.intersection(*[set(a), set(b)]))\n",
    "    uniao = len(set.union(*[set(a), set(b)]))\n",
    "    return intersecao / uniao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc877826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['gato', 'comeu', 'rato'], ['rato', 'comeu', 'comida', 'gato']]\n"
     ]
    }
   ],
   "source": [
    "corpus = [texto_1, texto_2]\n",
    "tokens = [texto.split() for texto in corpus]\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62072b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "similaridade = similaridade_jaccard(tokens[0], tokens[1])\n",
    "\n",
    "print(similaridade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similaridade_euclidiana(a, b):\n",
    "    if len(a) != len(b):\n",
    "        raise ValueError(\"Vetores a e b não possuem a mesma dimensao\")\n",
    "\n",
    "    distancia = math.sqrt(sum(math.pow(x - y, 2) for x, y in zip(a, b)))\n",
    "\n",
    "    return math.exp(-distancia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b06dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "vetorizador = CountVectorizer(stop_words=None)\n",
    "frequencias = vetorizador.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e6e6c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36787944117144233\n"
     ]
    }
   ],
   "source": [
    "similaridade = similaridade_euclidiana(\n",
    "    frequencias.toarray()[0], frequencias.toarray()[1]\n",
    ")\n",
    "print(similaridade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e221a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norma_vetor(x):\n",
    "    return math.sqrt(sum(a * a for a in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca8b6d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similaridade_cosseno(a, b):\n",
    "    if len(a) != len(b):\n",
    "        raise ValueError(\"Vetores a e b não possuem a mesma dimensao\")\n",
    "\n",
    "    numerador = sum(x * y for x, y in zip(a, b))\n",
    "    denominador = norma_vetor(a) * norma_vetor(b)\n",
    "\n",
    "    return numerador / denominador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c692053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8660254037844387\n"
     ]
    }
   ],
   "source": [
    "similaridade = similaridade_cosseno(frequencias.toarray()[0], frequencias.toarray()[1])\n",
    "\n",
    "print(similaridade)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
