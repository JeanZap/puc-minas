{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_ranknet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Learning to Rank**"
      ],
      "metadata": {
        "id": "u3csrRVa9B7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Técnica de ML usada para resolução de problemas de classificação. Uma das principais aplicações é em sistemas de busca (para e-commerce por exemplo), em que o objetivo é obter uma lista de itens claasificada, onde a ordem é importante.  "
      ],
      "metadata": {
        "id": "Ih7KrI0W9Gtu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em um sistema de busca, é importante que os resultados sejam ranqueados por relevância. "
      ],
      "metadata": {
        "id": "NKuX1YY6260d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RankNet é um algoritmo de Learning to Rank desenvolvido em 2005 por Chris Burges da Microsoft Research. O algoritmo pode ser implementado usando um rede neural que analisa pares de objetos. Sua função de custo tem como objetivo minimizar o número de trocas necessárias para melhorar uma ordenação incorreta na classificação de uma par de resultados.\n",
        "\n"
      ],
      "metadata": {
        "id": "OoiMz07y6as1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RankNet**"
      ],
      "metadata": {
        "id": "0gG16vu3y87s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEinbHvoy3gm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "from keras import backend\n",
        "from keras.layers import Activation, Add, Dense, Input, Lambda, Dropout, Subtract\n",
        "from keras.models import Model, Sequential\n",
        "from tensorflow.keras.utils import plot_model\n",
        "%pylab inline\n",
        "\n",
        "INPUT_DIM = 1536"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rede Base**"
      ],
      "metadata": {
        "id": "U26vEjPQkr1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A rede siamesa cria duas dessas redes base para itens de classificação mais alta e mais baixa, respectivamente."
      ],
      "metadata": {
        "id": "gwioE0H4ztRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para saber mais sobre redes siamesas:\n",
        "\n",
        "[Image similarity estimation using a Siamese Network with a triplet loss](https://keras.io/examples/vision/siamese_network/)\n",
        "\n",
        "[Siamese Neural Networks for One-shot Image Recognition](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)"
      ],
      "metadata": {
        "id": "oG-1IkgM0P5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_base_network(input_dim):\n",
        "    '''Base network to be shared (eq. to feature extraction).\n",
        "    '''\n",
        "    seq = Sequential()\n",
        "    seq.add(Dense(INPUT_DIM, input_shape=(input_dim,), activation='relu'))\n",
        "    seq.add(Dropout(0.1))\n",
        "    seq.add(Dense(64, activation='relu'))\n",
        "    seq.add(Dropout(0.1))\n",
        "    seq.add(Dense(32, activation='relu'))\n",
        "    seq.add(Dense(1))\n",
        "    return seq"
      ],
      "metadata": {
        "id": "JyenB5PZzqPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Arquitetura da rede siamesa**"
      ],
      "metadata": {
        "id": "hxzJJohJztxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "São criadas duas instâncias da arquitetura base e a diferença entre suas saídas são calculadas no final. \n",
        "\n",
        "A diferença será a entrada para uma função de classificação para o cálculo da loss."
      ],
      "metadata": {
        "id": "LWOCSsrFzt2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_meta_network(input_dim, base_network):\n",
        "    input_a = Input(shape=(input_dim,))\n",
        "    input_b = Input(shape=(input_dim,))\n",
        "\n",
        "    rel_score = base_network(input_a)\n",
        "    irr_score = base_network(input_b)\n",
        "\n",
        "    # subtract scores\n",
        "    diff = Subtract()([rel_score, irr_score])\n",
        "\n",
        "    # Pass difference through sigmoid function.\n",
        "    prob = Activation(\"sigmoid\")(diff)\n",
        "\n",
        "    # Build model.\n",
        "    model = Model(inputs = [input_a, input_b], outputs = prob)\n",
        "    model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "y_sYzMYBzuB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_network = create_base_network(INPUT_DIM)\n",
        "model = create_meta_network(INPUT_DIM, base_network)\n",
        "model.summary()\n",
        "\n",
        "plot_model(base_network, to_file='base.png')\n",
        "plot_model(model, to_file='meta.png')"
      ],
      "metadata": {
        "id": "vCA2Ty25zw4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset sintético**"
      ],
      "metadata": {
        "id": "SBIhvqx8zz9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O dataset será composto por dois conjuntos de dimensão \"N\" gerados aleatoriamente. "
      ],
      "metadata": {
        "id": "9EpcYcDYz2Bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fake data.\n",
        "N = 1000\n",
        "SPLIT=750\n",
        "X_1 = 2* np.random.randn(N, INPUT_DIM) # notice this data is shifted by 2\n",
        "X_2 = np.random.randn(N, INPUT_DIM)\n",
        "\n",
        "X_1_train = X_1[0:SPLIT,:]\n",
        "X_1_test = X_1[SPLIT:N,:]\n",
        "\n",
        "X_2_train = X_2[0:SPLIT,:]\n",
        "X_2_test =  X_2[SPLIT:N,:]\n",
        "\n",
        "\n",
        "y = np.ones((X_1.shape[0], 1))\n",
        "\n",
        "y_train = y[0:SPLIT,:]\n",
        "y_test = y[SPLIT:N,:]\n",
        "\n",
        "np.mean(X_1_train), np.mean(X_2_train)"
      ],
      "metadata": {
        "id": "CkKOrIZGz0MZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model.\n",
        "\n",
        "es=keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=2,\n",
        "                              verbose=1, mode='auto')\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 10\n",
        "history = model.fit([X_1_train, X_2_train], y_train, \n",
        "                    validation_data=([X_1_test, X_2_test], y_test), \n",
        "                    batch_size = BATCH_SIZE, epochs = NUM_EPOCHS, verbose = 1, callbacks=[es])"
      ],
      "metadata": {
        "id": "yqr0dHD-z6KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G-BR5Kosz-KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the mean score of the high-rank distribution should be higher\n",
        "np.mean(base_network.predict(X_1_test)), np.mean(base_network.predict(X_2_test))"
      ],
      "metadata": {
        "id": "HpjIWjjp0Aju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AUC\n",
        "(np.sum(base_network.predict(X_1_test) > base_network.predict(X_2_test))+0.0) / X_1_test.shape[0]"
      ],
      "metadata": {
        "id": "nHls_M9w0AvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(base_network.predict(X_1_test) > base_network.predict(X_2_test))"
      ],
      "metadata": {
        "id": "NJd56LlpTP8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Referência**\n",
        "\n",
        "[Learning to Rank from Pair-wise data](https://github.com/eggie5/RankNet)\n",
        "\n",
        "[Learning to Rank using Gradient Descent](https://icml.cc/2015/wp-content/uploads/2015/06/icml_ranking.pdf)\n"
      ],
      "metadata": {
        "id": "woV98meD0uwQ"
      }
    }
  ]
}